{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c31042-9b9f-4713-ad08-725d24616a04",
   "metadata": {},
   "source": [
    "steps to take:\n",
    "1. Install and import media pipe dependencies\n",
    "2. Determining Joints\n",
    "3. Calculating angles\n",
    "4. Curl counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be908f0f-01f7-48df-bd62-7e7ec6d970bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.11.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0445eb-0e11-45b9-8450-9ba279ef75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf32c6e-0007-419f-a6e9-d009e11867c9",
   "metadata": {},
   "source": [
    "Determining joints:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9744dc35-dd39-4442-a095-07a3b84a8068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Define the HTML content\n",
    "html_content = '<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\">'\n",
    "\n",
    "# Display the HTML content\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d184f5bd-31a0-4231-9a4a-c01519f5b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n",
    "\n",
    "# #video feed\n",
    "# cap = cv2.VideoCapture(0) #this number is the number of my web cam\n",
    "\n",
    "# #setup mediapipe instance\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read() \n",
    "    \n",
    "#         #detect stuff and render\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "#         image.flags.writeable = False #save a bunch of memory\n",
    "\n",
    "#         #make detections from the pose\n",
    "#         results = pose.process(image) #by processing it, we get our detections back\n",
    "    \n",
    "#         #back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         #extract landmarks\n",
    "#         try: \n",
    "#             landmarks = results.pose_landmarks.landmark #this will give us our landmark\n",
    "#             len(landmarks)\n",
    "\n",
    "#             shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "#             wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "#             calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "#             #render angle to the screen\n",
    "#             # cv2.putText(image, str(angle), tuple)\n",
    "#         except: \n",
    "#             pass\n",
    "    \n",
    "#         #render stuff now \n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "#         cv2.imshow('Mediapipe Feed', image)        \n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632d1795-86c0-424d-9dbe-b3fe071244fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7790dd-426f-41ab-9ccf-cb61bcc4485a",
   "metadata": {},
   "source": [
    "#need the angle between 11; 13; and 15 which is the angle for bicep curl\n",
    "#11: left shoulder ; 13: left elbow ; 15: left wrist\n",
    "3. Calculating angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a52b74-e76f-4b4e-a5ee-45f31857aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) #first point of the angle - shoulder for bicep curls\n",
    "    b = np.array(b) #mid point of the angle\n",
    "    c = np.array(c) #end point #converted them into numPy arrays\n",
    "    #arctan2 calculates the angle between positive x axis and the point (x,y)\n",
    "    # np.arctan2(c[1]-b[1], c[0] - b[0]) calculates the angle bw vector cb and x axis\n",
    "    # np.arctan2(a[1]-b[1], a[0] - b[0] calculayes the angle bw vector ab and x axis\n",
    "    radians = np.arctan2(c[1]-b[1], c[0] - b[0]) - np.arctan2(a[1]-b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180/np.pi) # convert radians to degree\n",
    "\n",
    "    if angle < 0:\n",
    "            angle += 360\n",
    "            if angle > 180:\n",
    "                angle = 360 - angle \n",
    "    elif angle > 180:\n",
    "        angle = 360 - angle\n",
    "\n",
    "\n",
    "    # cv2.line(img, (a[0], a[1]), (b[0], b[1]), (255,255,255), 3)\n",
    "    # cv2.line(img, (c[0], c[1]), (b[0], b[1]), (255,255,255), 3)\n",
    "\n",
    "            \n",
    "    # cv2.circle(img, (a[0], a[1]), 5, (0,0,255), cv2.FILLED)\n",
    "    # cv2.circle(img, (a[0], a[1]), 15, (0,0,255), 2)\n",
    "    # cv2.circle(img, (b[0], b[1]), 5, (0,0,255), cv2.FILLED)\n",
    "    # cv2.circle(img, (b[0], b[1]), 15, (0,0,255), 2)\n",
    "    # cv2.circle(img, (c[0], c[1]), 5, (0,0,255), cv2.FILLED)\n",
    "    # cv2.circle(img, (c[0], c[1]), 15, (0,0,255), 2)  \n",
    "    # print(angle)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7bf876-839a-4a53-8e89-8ed2f1b0d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "# elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "# wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd5d4b8-b3df-48bc-8d20-24f5142229ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder, elbow, wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251d3bf1-aae2-4ed8-977b-2fff1093fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea179e24-ebef-42ca-9c7c-89d1ddf098b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "# hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "# elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f77e0a-31bd-4eca-8f80-64a5b937d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_angle(hip, shoulder, elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045d8b6d-395c-4e2a-8aea-84fe65ed4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple(np.multiply(elbow, [640, 480]).astype(int)) # [640,480] dimentions of my screen so to get the actual corrdinates, we multiply the corrdinates with dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6911ef63-2299-4cc1-94a0-b427fc6fdca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread() \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#detect stuff and render\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB) \n\u001b[0;32m     20\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m#save a bunch of memory\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#make detections from the pose\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n",
    "\n",
    "#video feed\n",
    "cap = cv2.VideoCapture(0) #this number is the number of my web cam\n",
    "\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "#setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() \n",
    "    \n",
    "        #detect stuff and render\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        image.flags.writeable = False #save a bunch of memory\n",
    "\n",
    "        #make detections from the pose\n",
    "        results = pose.process(image) #by processing it, we get our detections back\n",
    "    \n",
    "        #back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #extract landmarks\n",
    "        try: \n",
    "            landmarks = results.pose_landmarks.landmark #this will give us our landmark\n",
    "            len(landmarks)\n",
    "\n",
    "            print(1)\n",
    "\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            #render angle to the screen\n",
    "            cv2.putText(image, str(angle), \n",
    "                               tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                    )\n",
    "\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                counter += 1\n",
    "                print(counter)\n",
    "        except: \n",
    "            pass\n",
    "            print(error)\n",
    "\n",
    "        #render curl count\n",
    "        cv2.rectangle(image, (0,0), (225, 73), (0,0,0), -1) # -1 will fill the color \n",
    "\n",
    "        #red data\n",
    "        cv2.putText(image, \"REPS\", (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        #stage data\n",
    "        cv2.putText(image, \"STAGE\", (65,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, stage, (60,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        #render stuff now \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46c8db-d440-4087-bf6e-e776d05c4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #this is where we are importing the pre-built pose detection model from mediapipe\n",
    "\n",
    "#video feed\n",
    "cap = cv2.VideoCapture(0) #this number is the number of my web cam\n",
    "\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "feedback = 'Wrong form'\n",
    "form = 0\n",
    "\n",
    "\n",
    "#setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() \n",
    "    \n",
    "        #detect stuff and render\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        image.flags.writeable = False #save a bunch of memory\n",
    "\n",
    "        #make detections from the pose\n",
    "        results = pose.process(image) #by processing it, we get our detections back\n",
    "    \n",
    "        #back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #extract landmarks\n",
    "        try: \n",
    "            landmarks = results.pose_landmarks.landmark #this will give us our landmark\n",
    "            len(landmarks)\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            \n",
    "            angleElbow = calculate_angle(left_wrist, left_elbow, left_shoulder)\n",
    "            angleShoulder = calculate_angle(left_elbow, left_shoulder, left_hip)\n",
    "            angleHip = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "\n",
    "            print(angleElbow)\n",
    "\n",
    "            #render angle to the screen\n",
    "            # cv2.putText(image, str(angle), tuple(np.multiply(elbow, [640, 480]).astype(int)), cv2.FONT_HERSHEY_SIMPLE, 0.5, (0,0,0), 2, cv2.LINE_AA)\n",
    "            # print(landmarks)\n",
    "            cv2.putText(image, str(angleElbow), \n",
    "                               tuple(np.multiply(left_elbow, [640, 480]).astype(int)), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                    )\n",
    "            cv2.putText(image, str(angleShoulder), \n",
    "                               tuple(np.multiply(left_shoulder, [640, 480]).astype(int)), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                    )\n",
    "            cv2.putText(image, str(angleHip), \n",
    "                               tuple(np.multiply(left_hip, [640, 480]).astype(int)), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                    )\n",
    "\n",
    "           # np.interp() function then linearly interpolates the value of elbow \n",
    "            # within the range (90, 160) to find its corresponding value within the range (0, 100).\n",
    "\n",
    "            successPercentage = np.interp(angleElbow, (90, 160), (0, 100)) #will be 0 in down position\n",
    "\n",
    "            if angleElbow > 160 and angleShoulder > 45 and angleHip > 160:\n",
    "                form = 1\n",
    "\n",
    "            if form == 1:\n",
    "                if successPercentage == 0: # success% will be 0 in down position\n",
    "                    if angleElbow <= 90 and hip > 160:\n",
    "                        feedback = \"Go up\"\n",
    "                        if angleElbow > 90 and stage == \"down\":\n",
    "                            stage = \"up\"\n",
    "                            counter += 1\n",
    "                    \n",
    "                    else:\n",
    "                        feedback = \"wrong form\"\n",
    "\n",
    "                if successPercentage == 100: # up position\n",
    "                    if angleElbow > 160 and angleShoulder > 45 and angleHip > 160:\n",
    "                        feedback = \"Go down\"\n",
    "                        if stage == \"up\" and angleElbow <= 90:\n",
    "                            counter += 1\n",
    "                            stage = \"down\"      \n",
    "                        \n",
    "                    else:\n",
    "                        feedback = \"Wrong form\"\n",
    "                        \n",
    "        except: \n",
    "            pass\n",
    "\n",
    "        #render curl count\n",
    "        cv2.rectangle(image, (0,0), (225, 73), (0,0,0), -1) # -1 will fill the color \n",
    "\n",
    "        #red data\n",
    "        cv2.putText(image, \"REPS\", (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        #stage data\n",
    "        cv2.putText(image, \"STAGE\", (65,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, stage, (60,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        #Feedback data\n",
    "        cv2.putText(image, \"FEEDBACK\", (115,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, feedback, (110,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # #render stuff now \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        # cv2.line(img, \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48daa82-8f7d-4da2-a862-6b640d5417c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
